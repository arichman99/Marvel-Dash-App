{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d84514",
   "metadata": {},
   "source": [
    "# Marvel Character and Comic Explorer\n",
    "\n",
    "This Dash application allows users to explore Marvel Comics characters, their comic appearances, and connections to major events. It uses the Marvel Comics API and a static CSV for redundancy. The app is designed to be deployment-ready with a polished interface and explanatory visualizations.\n",
    "\n",
    "## Requirements\n",
    "- Install: `pip install dash plotly pandas requests dash-bootstrap-components python-dotenv beautifulsoup4 fuzzywuzzy wordcloud`\n",
    "- Register at [Marvel Developer Portal](https://developer.marvel.com/) for API keys.\n",
    "- Store keys in `.env`:\n",
    "> - MARVEL_PUBLIC_KEY=your_public_key\n",
    "> - MARVEL_PRIVATE_KEY=your_private_key\n",
    "\n",
    "## Data\n",
    "- **Source**: Marvel Comics API (characters, comics, events).\n",
    "- **Static Backup**: `data/marvel_data.csv` (included in repo). Use this to avoid ~1-hour API scraping (see Data Loading Note below).\n",
    "- **Character List**: Scraped from Comic Vine’s “Top 300 Most Published Marvel Characters”.\n",
    "\n",
    "## Features\n",
    "- **Components**: Dropdown (characters), Checklist (comic format), Date Picker Range (publication dates), Text Input (search comics/events).\n",
    "- **Visualizations**: Bar chart (appearances), Line chart (trends), Network graph (character-event connections).\n",
    "- **Interactivity**: Updates via a single callback.\n",
    "- **Narrative**: Guides users through exploring Marvel's universe.\n",
    "\n",
    "## Limitations\n",
    "- **Character Aliases**: Some characters have multiple aliases (e.g., Spider-Man, Peter Parker, Miles Morales), which are not aggregated. For example, \"Spider-Man\" appears in ~400 comics in the CSV, but has many more under different names. This is due to the complexity of mapping aliases in the Marvel API and Comic Vine data.\n",
    "- **API Constraints**: The Marvel API has a 3,000 calls/day limit.\n",
    "\n",
    "## Instructions for Running\n",
    "1. Save as `marvel_dash_app.ipynb`.\n",
    "2. Place `data/marvel_data.csv` in `data/` or generate via Cell 4.\n",
    "3. Install: `pip install -r requirements.txt`.\n",
    "4. Set up `.env` with API keys.\n",
    "5. Run all cells. Access at `http://127.0.0.1:8050`.\n",
    "\n",
    "**Troubleshooting**: Check dependencies and API keys if the app fails to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cdbcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and set up environment\n",
    "import os\n",
    "import requests\n",
    "import hashlib\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from dash import Dash, dcc, html, Input, Output, State\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash_bootstrap_components as dbc\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from fuzzywuzzy import process\n",
    "import unicodedata\n",
    "from wordcloud import WordCloud\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()\n",
    "public_key = os.getenv('MARVEL_PUBLIC_KEY', 'your_public_key')\n",
    "private_key = os.getenv('MARVEL_PRIVATE_KEY', 'your_private_key')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_for_fuzzy(s):\n",
    "    \"\"\"\n",
    "    Normalize string for fuzzy matching by removing non-alphanumeric characters,\n",
    "    converting to lowercase, and normalizing unicode characters.\n",
    "    \n",
    "    Args:\n",
    "        s (str): input string to normalize.\n",
    "    Returns:\n",
    "        str: normalized string suitable for fuzzy matching.\n",
    "    \"\"\"\n",
    "    \n",
    "    s = s.lower()\n",
    "    s = re.sub(r'\\W+', '', s) \n",
    "    s = unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('ascii')\n",
    "    return s\n",
    "\n",
    "def standardize_name(name):\n",
    "    \"\"\"\n",
    "    Standardizes character names by removing unnecessary content, correcting common\n",
    "    formatting issues, and applying consistent capitalization.\n",
    "\n",
    "    Args:\n",
    "        name (str): character name to standardize.\n",
    "    Returns:\n",
    "        str: standardized character name, or None if input is invalid.\n",
    "    \"\"\"\n",
    "\n",
    "    if not name or pd.isna(name):\n",
    "        return None\n",
    "\n",
    "    # remove escaped quotes and parentheses content\n",
    "    name = re.sub(r'\\\\\"', '', name)\n",
    "    name = re.sub(r'\\(.*?\\)', '', name)\n",
    "\n",
    "    # remove extra spaces and strip\n",
    "    name = re.sub(r'\\s+', ' ', name).strip().lower()\n",
    "\n",
    "    # manual replacements for known cases\n",
    "    replacements = {\n",
    "        'spiderman': 'Spider-Man',\n",
    "        'ironman': 'Iron Man',\n",
    "        'captainamerica': 'Captain America',\n",
    "        'dr. strange': 'Doctor Strange',\n",
    "        'dr strange': 'Doctor Strange',\n",
    "        'antman': 'Ant-Man',\n",
    "        'blackwidow': 'Black Widow',\n",
    "        'wolverine': 'Wolverine',\n",
    "        'ms. marvel': 'Ms. Marvel',\n",
    "        'nick fury': 'Nick Fury',\n",
    "        'jean grey': 'Jean Grey',\n",
    "        'hawkeye': 'Hawkeye',\n",
    "        'captain marvel': 'Captain Marvel',\n",
    "        'scarlet witch': 'Scarlet Witch',\n",
    "        'deadpool': 'Deadpool',\n",
    "    }\n",
    "    if name in replacements:\n",
    "        return replacements[name]\n",
    "\n",
    "    # capitalize hyphenated names correctly\n",
    "    if '-' in name:\n",
    "        name = '-'.join(part.capitalize() for part in name.split('-'))\n",
    "    else:\n",
    "        name = ' '.join(part.capitalize() for part in name.split())\n",
    "\n",
    "    return name\n",
    "\n",
    "def scrape_comicvine_characters():\n",
    "    \"\"\"\n",
    "    Scrapes top 300 most published Marvel characters from ComicVine.\n",
    "    Returns:\n",
    "        list: list of standardized character names.\n",
    "    \"\"\"\n",
    "    # set up base URL and prepare to scrape\n",
    "    base_url = \"https://comicvine.gamespot.com/profile/moonofcomics/lists/top-300-most-published-marvel-characters/80119/\"\n",
    "    all_character_names = []\n",
    "\n",
    "    for page in range(1, 5):\n",
    "        url = base_url if page == 1 else f\"{base_url}?page={page}\"\n",
    "        print(f\"Scraping page {page} ...\")\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # find all <h3> tags, filter and clean names\n",
    "        h3_tags = soup.find_all(\"h3\")\n",
    "        for h3 in h3_tags:\n",
    "            name = h3.get_text(strip=True)\n",
    "            if name.lower() != \"stan lee\":  # skip \"Stan Lee\" honorable mention\n",
    "                std_name = standardize_name(name)\n",
    "                if std_name:\n",
    "                    all_character_names.append(std_name)\n",
    "\n",
    "    # deduplicate and sort\n",
    "    unique_names = sorted(set(all_character_names))\n",
    "    return unique_names\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to scrape character names and save them to a CSV file.\n",
    "    \"\"\"\n",
    "    \n",
    "    names = scrape_comicvine_characters()\n",
    "    print(f\"Total unique characters scraped: {len(names)}\")\n",
    "\n",
    "    df = pd.DataFrame({'standardized_name': names})\n",
    "    df.to_csv(\"top_marvel_characters.csv\", index=False)\n",
    "    print(\"✅ Saved standardized character names to top_marvel_characters.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_comics_for_character(char_id, base_url, public_key, private_key):\n",
    "    \"\"\"\n",
    "    Fetch all comics for a character from Marvel API.\n",
    "\n",
    "    Args:\n",
    "        char_id (int): character ID.\n",
    "        base_url (str): API base URL.\n",
    "        public_key (str): public API key.\n",
    "        private_key (str): private API key.\n",
    "\n",
    "    Returns:\n",
    "        list: list of comic data dictionaries.\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "    \n",
    "    all_comics = []\n",
    "    limit = 50\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        ts = str(int(time.time()))\n",
    "        hash_val = hashlib.md5((ts + private_key + public_key).encode()).hexdigest()\n",
    "\n",
    "        comics_url = (\n",
    "            f\"{base_url}characters/{char_id}/comics\"\n",
    "            f\"?ts={ts}&apikey={public_key}&hash={hash_val}&limit={limit}&offset={offset}\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = session.get(comics_url, timeout=10)  # set explicit timeout\n",
    "            response.raise_for_status()\n",
    "            data = response.json().get('data', {})\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"  Timeout fetching comics at offset {offset} for character ID {char_id}. Skipping this batch.\")\n",
    "            offset += limit  # move to next batch\n",
    "            time.sleep(1)  # longer delay before retrying\n",
    "            continue\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"  Error fetching comics at offset {offset} for character ID {char_id}: {e}\")\n",
    "            break  # stop on non-timeout errors\n",
    "\n",
    "        comics = data.get('results', [])\n",
    "        all_comics.extend(comics)\n",
    "        print(f\"  Fetched {len(comics)} comics at offset {offset} (total: {len(all_comics)})\")\n",
    "\n",
    "        total = data.get('total', 0)\n",
    "        count = data.get('count', 0)\n",
    "        offset += count\n",
    "\n",
    "        if offset >= total or count == 0:\n",
    "            break\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    return all_comics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_marvel_data_from_list(filename='top_marvel_characters.csv'):\n",
    "    \"\"\"\n",
    "    Fetch comic data for a list of Marvel characters from Marvel API and save to CSV.\n",
    "\n",
    "    Args:\n",
    "        filename (str): path to CSV file containing character names (default: 'top_marvel_characters.csv').\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: df containing fetched comic data.\n",
    "    \"\"\"\n",
    "    if not public_key or not private_key:\n",
    "        raise ValueError(\"Invalid API keys. Please set MARVEL_PUBLIC_KEY and MARVEL_PRIVATE_KEY in .env.\")\n",
    "\n",
    "    df_names = pd.read_csv(filename)\n",
    "    character_names = df_names['standardized_name'].dropna().unique().tolist()\n",
    "\n",
    "    base_url = 'https://gateway.marvel.com/v1/public/'\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for name in character_names:\n",
    "        ts = str(int(time.time()))\n",
    "        hash_val = hashlib.md5((ts + private_key + public_key).encode()).hexdigest()\n",
    "        search_url = f\"{base_url}characters?ts={ts}&apikey={public_key}&hash={hash_val}&nameStartsWith={name}\"\n",
    "\n",
    "        print(f\"Searching for {name}...\")\n",
    "        try:\n",
    "            response = session.get(search_url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            results = response.json().get('data', {}).get('results', [])\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"  Timeout searching for {name}. Skipping.\")\n",
    "            continue\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"  Error fetching data for {name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if not results:\n",
    "            print(f\"  No matches found for {name}\")\n",
    "            continue\n",
    "\n",
    "        # fuzzy matching to find best match\n",
    "        all_names = [char['name'] for char in results]\n",
    "        best_match, score = process.extractOne(name, all_names)\n",
    "\n",
    "        if score < 70:\n",
    "            print(f\"  Low confidence match for {name}: {best_match} (score: {score})\")\n",
    "            continue\n",
    "\n",
    "        matched_char = next((char for char in results if char['name'] == best_match), None)\n",
    "        if not matched_char:\n",
    "            continue\n",
    "\n",
    "        char_id = matched_char['id']\n",
    "\n",
    "        try:\n",
    "            comics = fetch_all_comics_for_character(char_id, base_url, public_key, private_key)\n",
    "            print(f\"  Successfully fetched {len(comics)} comics for character {best_match}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error fetching comics for {best_match}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for comic in comics:\n",
    "            dates = comic.get('dates', [])\n",
    "            on_sale_date = next((d['date'] for d in dates if d['type'] == 'onsaleDate'), '1900-01-01')\n",
    "            events_items = comic.get('events', {}).get('items', [])\n",
    "            event_name = events_items[0]['name'] if events_items else 'None'\n",
    "\n",
    "            data.append({\n",
    "                'character': best_match,\n",
    "                'comic_title': comic['title'],\n",
    "                'format': comic.get('format', 'Comic'),\n",
    "                'date': pd.to_datetime(on_sale_date, errors='coerce'),\n",
    "                'event': event_name\n",
    "            })\n",
    "\n",
    "        time.sleep(1)  # increased delay between characters\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    if not df.empty:\n",
    "        os.makedirs('data', exist_ok=True)\n",
    "        df.to_csv('data/marvel_data.csv', index=False)\n",
    "        print(f\"\\n✅ Successfully created marvel_data.csv with {len(df)} records\")\n",
    "    else:\n",
    "        print(\"⚠️ No data fetched. CSV not created.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cede0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load Marvel data from CSV file if it exists, otherwise fetch from API.\n",
    "    Returns:\n",
    "        pandas.DataFrame: df containing Marvel comic data.\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.exists('data/marvel_data.csv'):\n",
    "        print(\"Loading data from static CSV: data/marvel_data.csv\")\n",
    "        df = pd.read_csv('data/marvel_data.csv', parse_dates=['date'])\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        df.dropna(subset=['date'], inplace=True)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Static CSV not found. Fetching data from Marvel API (this may take ~1 hour)...\")\n",
    "        return fetch_marvel_data_from_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a2f5d",
   "metadata": {},
   "source": [
    "## Data Loading Note\n",
    "\n",
    "The next cell (`df = load_data()`) loads the Marvel Comics data. By default, it uses the static file `data/marvel_data.csv` if available. If the file is missing, it will fetch data from the Marvel API, which can take **approximately 1 hour** due to the large number of characters and API rate limits (3,000 calls/day).\n",
    "\n",
    "**Options**:\n",
    "- **Use the Static CSV**: Ensure `data/marvel_data.csv` is in the `data/` folder (included in the repository). This is the fastest way to run the app without scraping.\n",
    "- **Fetch Fresh Data**: If you prefer to scrape the latest data, ensure valid API keys are set in `.env`. Be prepared for a long runtime and potential API limit issues.\n",
    "\n",
    "**Recommendation**: Use the provided `data/marvel_data.csv` unless you specifically need fresh data. To generate a new CSV, run the cell below, but allow sufficient time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b2eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Dash app\n",
    "app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP, 'https://fonts.googleapis.com/css2?family=Bangers&display=swap'])\n",
    "\n",
    "# define layout\n",
    "app.layout = dbc.Container([\n",
    "    # marvel logo\n",
    "    html.Img(\n",
    "        src='https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Marvel_Logo.svg/960px-Marvel_Logo.svg.png?20161025051221',\n",
    "        style={'width': '200px', 'display': 'block', 'margin': 'auto'}\n",
    "    ),\n",
    "    # title\n",
    "    html.H1('Marvel Comics Universe Explorer', className='text-center my-4', style={'fontFamily': 'Bangers, cursive', 'color': '#E6242A'}),\n",
    "    # introductory text\n",
    "    html.P(\n",
    "        'Dive into the Marvel Comics universe! Select a character to explore their comic appearances, filter by format or date range, '\n",
    "        'and search for specific comics or events (e.g., \"Civil War\"). '\n",
    "        'The charts below show appearance counts, publication trends, and character-event connections.',\n",
    "        className='text-center mb-4', style={'fontSize': '16px'}\n",
    "    ),\n",
    "\n",
    "    # summary card\n",
    "    dbc.Card([\n",
    "        dbc.CardBody([\n",
    "            html.H4(\"Character Summary\", className=\"card-title\"),\n",
    "            html.P(id='summary-text', className=\"card-text\")\n",
    "        ])\n",
    "    ], style={'marginBottom': '20px', 'backgroundColor': '#F8F9FA'}),\n",
    "\n",
    "    # input components\n",
    "    dbc.Card([\n",
    "        dbc.CardBody([\n",
    "            dbc.Row([\n",
    "                dbc.Col([html.Label('Select Character', style={'color': '#E6242A'}), dcc.Dropdown(id='character-dropdown')], width=4),\n",
    "                dbc.Col([html.Label('Comic Format', style={'color': '#E6242A'}), dcc.Checklist(id='format-checklist', inline=True)], width=4),\n",
    "                dbc.Col([html.Label('Search Comic/Event', style={'color': '#E6242A'}), dcc.Input(id='search-input', type='text', placeholder='e.g., Civil War')], width=4)\n",
    "            ], className='mb-3'),\n",
    "            dbc.Row([\n",
    "                dbc.Col([html.Label('Publication Date Range', style={'color': '#E6242A'}), dcc.DatePickerRange(id='date-range')], width=12)\n",
    "            ])\n",
    "        ])\n",
    "    ], style={'backgroundColor': '#F8F9FA', 'padding': '20px', 'marginBottom': '20px'}),\n",
    "\n",
    "    # controls\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Label('Chart Style'),\n",
    "            dcc.RadioItems(\n",
    "                id='theme-toggle',\n",
    "                options=[{'label': 'Light', 'value': 'light'}, {'label': 'Dark', 'value': 'dark'}],\n",
    "                value='light',\n",
    "                inline=True\n",
    "            ),\n",
    "            html.Button('Reset Filters', id='reset-button', n_clicks=0, className='btn btn-danger mt-2'),\n",
    "            html.Button('Download Filtered Data', id='download-button', n_clicks=0, className='btn btn-primary mt-2 ml-2'),\n",
    "            dcc.Download(id='download-data')\n",
    "        ])\n",
    "    ], className='my-3'),\n",
    "\n",
    "    # graphs\n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(id='bar-chart'), width=6),\n",
    "        dbc.Col(dcc.Graph(id='line-chart'), width=6)\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(id='network-graph'), width=12)\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col(html.Img(id='wordcloud'), width=12, className='text-center')\n",
    "    ]),\n",
    "    html.Div(id='peak-year', className='text-center my-2 font-weight-bold'),\n",
    "\n",
    "    # captions\n",
    "    html.P('Left: Comic appearances for selected character. Right: Publication trends over time.', className='text-center'),\n",
    "    html.P('Character-event connections across the Marvel universe.', className='text-center'),\n",
    "    html.P('Word cloud of comic titles for the selected filters.', className='text-center')\n",
    "\n",
    "], fluid=True)\n",
    "\n",
    "# callback for reset button\n",
    "@app.callback(\n",
    "    [Output('character-dropdown', 'options'),\n",
    "     Output('character-dropdown', 'value'),\n",
    "     Output('format-checklist', 'options'),\n",
    "     Output('format-checklist', 'value'),\n",
    "     Output('date-range', 'min_date_allowed'),\n",
    "     Output('date-range', 'max_date_allowed'),\n",
    "     Output('date-range', 'start_date'),\n",
    "     Output('date-range', 'end_date'),\n",
    "     Output('search-input', 'value')],\n",
    "    [Input('reset-button', 'n_clicks')]\n",
    ")\n",
    "\n",
    "# callback to initialize or reset dropdowns and date range\n",
    "def initialize_or_reset(n_clicks):\n",
    "    \"\"\"\n",
    "    Initialize or reset dropdowns and date range inputs.\n",
    "    Args:\n",
    "        n_clicks (int): number of times reset button has been clicked.\n",
    "    Returns:\n",
    "        tuple: contains options for character dropdown, selected character, format checklist options,\n",
    "               selected formats, min and max dates for date range, start and end dates, and search input value.\n",
    "    \"\"\"\n",
    "    characters = [{'label': c, 'value': c} for c in df['character'].dropna().unique()]\n",
    "    formats_unique = df['format'].dropna().unique()\n",
    "    formats = [{'label': f, 'value': f} for f in formats_unique]\n",
    "    min_date = df['date'].min()\n",
    "    max_date = df['date'].max()\n",
    "\n",
    "    return characters, df['character'].dropna().unique()[0], formats, list(formats_unique), min_date, max_date, min_date, max_date, ''\n",
    "\n",
    "# generate word cloud\n",
    "def generate_wordcloud(text, theme):\n",
    "    \"\"\"\n",
    "    Generate a word cloud image from a list of comic titles.\n",
    "    Args:\n",
    "        text (list): list of comic titles.\n",
    "        theme (str): theme for background color ('light' or 'dark').\n",
    "    Returns:\n",
    "        str: base64 encoded image source for word cloud.\n",
    "    \"\"\"\n",
    "    bg_color = 'white' if theme == 'light' else '#333333'\n",
    "    wc = WordCloud(width=600, height=400, background_color=bg_color).generate(' '.join(text))\n",
    "    buf = BytesIO()\n",
    "    wc.to_image().save(buf, format='PNG')\n",
    "    data = base64.b64encode(buf.getvalue()).decode()\n",
    "    return f'data:image/png;base64,{data}'\n",
    "\n",
    "# main callback for updating plots and summary\n",
    "@app.callback(\n",
    "    [Output('bar-chart', 'figure'),\n",
    "     Output('line-chart', 'figure'),\n",
    "     Output('network-graph', 'figure'),\n",
    "     Output('wordcloud', 'src'),\n",
    "     Output('peak-year', 'children'),\n",
    "     Output('summary-text', 'children')],\n",
    "    [Input('character-dropdown', 'value'),\n",
    "     Input('format-checklist', 'value'),\n",
    "     Input('date-range', 'start_date'),\n",
    "     Input('date-range', 'end_date'),\n",
    "     Input('search-input', 'value'),\n",
    "     Input('theme-toggle', 'value')]\n",
    ")\n",
    "\n",
    "def update_plots(character, formats, start_date, end_date, search, theme):\n",
    "    \"\"\"\n",
    "    Update bar chart, line chart, network graph, word cloud, peak year message, and summary card based on user inputs.\n",
    "    Args:\n",
    "        character (str): selected character name.\n",
    "        formats (list): selected comic formats.\n",
    "        start_date (str): start date for filtering comics.\n",
    "        end_date (str): end date for filtering comics.\n",
    "        search (str): search term for comics or events.\n",
    "        theme (str): theme for plots ('light' or 'dark').\n",
    "    Returns:\n",
    "        tuple: updated bar chart, line chart, network graph, word cloud source, peak year message, and summary text.\n",
    "    \"\"\"\n",
    "    if character is None:\n",
    "        character = df['character'].unique()[0]\n",
    "    if formats is None:\n",
    "        formats = df['format'].unique().tolist()\n",
    "    if start_date is None:\n",
    "        start_date = df['date'].min()\n",
    "    if end_date is None:\n",
    "        end_date = df['date'].max()\n",
    "\n",
    "    template = 'plotly_dark' if theme == 'dark' else 'plotly_white'\n",
    "\n",
    "    filtered_df = df[\n",
    "        (df['character'] == character) &\n",
    "        (df['format'].isin(formats)) &\n",
    "        (df['date'] >= start_date) &\n",
    "        (df['date'] <= end_date)\n",
    "    ]\n",
    "\n",
    "    if search:\n",
    "        filtered_df = filtered_df[\n",
    "            filtered_df['comic_title'].str.contains(search, case=False, na=False) |\n",
    "            filtered_df['event'].str.contains(search, case=False, na=False)\n",
    "        ]\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        bar_fig = px.bar(title='No data available for the selected filters.')\n",
    "        bar_fig.update_layout(\n",
    "            xaxis_title='Character',\n",
    "            yaxis_title='Number of Appearances',\n",
    "            font=dict(family='Arial', size=12),\n",
    "            template=template\n",
    "        )\n",
    "        line_fig = px.line(title='No data available for the selected filters.')\n",
    "        line_fig.update_layout(\n",
    "            xaxis_title='Publication Date',\n",
    "            yaxis_title='Number of Comics',\n",
    "            font=dict(family='Arial', size=12),\n",
    "            template=template\n",
    "        )\n",
    "        network_fig = go.Figure().add_annotation(\n",
    "            text='No data available.',\n",
    "            showarrow=False,\n",
    "            xref='paper', yref='paper',\n",
    "            x=0.5, y=0.5,\n",
    "            font=dict(size=20)\n",
    "        )\n",
    "        network_fig.update_layout(\n",
    "            title='Character-Event Connections',\n",
    "            showlegend=False,\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            font=dict(family='Arial', size=12),\n",
    "            template=template\n",
    "        )\n",
    "        wordcloud_src = ''\n",
    "        peak_msg = 'No data to determine peak year.'\n",
    "        summary_text = 'No data available.'\n",
    "    else:\n",
    "        # bar chart: comic appearances\n",
    "        bar_data = filtered_df.groupby('character').size().reset_index(name='appearances')\n",
    "        bar_fig = px.bar(\n",
    "            bar_data,\n",
    "            x='character',\n",
    "            y='appearances',\n",
    "            title=f'Comic Appearances for {character}',\n",
    "            color_discrete_sequence=['#E6242A']\n",
    "        )\n",
    "        bar_fig.update_layout(\n",
    "            xaxis_title='Character',\n",
    "            yaxis_title='Number of Appearances',\n",
    "            font=dict(family='Arial', size=12),\n",
    "            template=template\n",
    "        )\n",
    "\n",
    "        # line chart: yearly comic releases\n",
    "        line_data = filtered_df.groupby(filtered_df['date'].dt.year).size().reset_index(name='comic_count')\n",
    "        line_fig = px.line(\n",
    "            line_data,\n",
    "            x='date',\n",
    "            y='comic_count',\n",
    "            title=f'Yearly Comic Releases for {character}',\n",
    "            markers=True,\n",
    "            color_discrete_sequence=['#FFD700']\n",
    "        )\n",
    "        line_fig.update_layout(\n",
    "            xaxis_title='Year',\n",
    "            yaxis_title='Number of Comics',\n",
    "            font=dict(family='Arial', size=12),\n",
    "            template=template,\n",
    "            yaxis_type='linear'\n",
    "        )\n",
    "\n",
    "        # network graph: character-event connections\n",
    "        network_data = filtered_df[filtered_df['event'] != 'None'][['character', 'event']].drop_duplicates()\n",
    "        nodes = list(set(network_data['character']).union(set(network_data['event'])))\n",
    "        node_dict = {n: i for i, n in enumerate(nodes)}\n",
    "        edges = [(node_dict[row['character']], node_dict[row['event']]) for _, row in network_data.iterrows()]\n",
    "\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from([(row['character'], row['event']) for _, row in network_data.iterrows()])\n",
    "        pos = nx.kamada_kawai_layout(G)\n",
    "        x_nodes = [pos[node][0] for node in nodes]\n",
    "        y_nodes = [pos[node][1] for node in nodes]\n",
    "        network_fig = go.Figure()\n",
    "        for edge in edges:\n",
    "            x0, y0 = x_nodes[edge[0]], y_nodes[edge[0]]\n",
    "            x1, y1 = x_nodes[edge[1]], y_nodes[edge[1]]\n",
    "            network_fig.add_trace(go.Scatter(\n",
    "                x=[x0, x1, None],\n",
    "                y=[y0, y1, None],\n",
    "                mode='lines',\n",
    "                line=dict(color='gray', width=1),\n",
    "                hoverinfo='none'\n",
    "            ))\n",
    "        network_fig.add_trace(go.Scatter(\n",
    "            x=x_nodes,\n",
    "            y=y_nodes,\n",
    "            mode='markers+text',\n",
    "            text=nodes,\n",
    "            marker=dict(size=20, color=['#E6242A' if 'event' not in str(n) else '#FFD700' for n in nodes]),\n",
    "            textposition='top center',\n",
    "            hovertemplate='%{text}<br>Type: %{customdata}<extra></extra>',\n",
    "            customdata=['Character' if 'event' not in str(n) else 'Event' for n in nodes]\n",
    "        ))\n",
    "        network_fig.update_layout(\n",
    "            title='Character-Event Connections',\n",
    "            showlegend=False,\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            font=dict(family='Arial', size=12),\n",
    "            margin=dict(l=20, r=20, t=40, b=20),\n",
    "            template=template\n",
    "        )\n",
    "\n",
    "        # word cloud\n",
    "        wordcloud_src = generate_wordcloud(filtered_df['comic_title'].dropna().tolist(), theme) if not filtered_df.empty else ''\n",
    "\n",
    "        # peak year message\n",
    "        peak_msg = f\"Peak comic activity: {filtered_df['date'].dt.year.value_counts().idxmax()}\"\n",
    "\n",
    "        # summary text\n",
    "        total_appearances = len(filtered_df)\n",
    "        unique_events = filtered_df['event'].nunique()\n",
    "        top_format = filtered_df['format'].mode()[0] if not filtered_df['format'].empty else 'N/A'\n",
    "        summary_text = (\n",
    "            f\"Total Comics: {total_appearances} | \"\n",
    "            f\"Unique Events: {unique_events} | \"\n",
    "            f\"Top Format: {top_format}\"\n",
    "        )\n",
    "\n",
    "    return bar_fig, line_fig, network_fig, wordcloud_src, peak_msg, summary_text\n",
    "\n",
    "# callback for download button\n",
    "@app.callback(\n",
    "    Output('download-data', 'data'),\n",
    "    Input('download-button', 'n_clicks'),\n",
    "    State('character-dropdown', 'value'),\n",
    "    State('format-checklist', 'value'),\n",
    "    State('date-range', 'start_date'),\n",
    "    State('date-range', 'end_date'),\n",
    "    State('search-input', 'value'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def download_data(n_clicks, character, formats, start_date, end_date, search):\n",
    "    \"\"\"\n",
    "    Generate a CSV file of filtered dataset for download.\n",
    "    Args:\n",
    "        n_clicks (int): number of times download button was clicked.\n",
    "        character (str): selected character.\n",
    "        formats (list): selected formats.\n",
    "        start_date (str): start date.\n",
    "        end_date (str): end date.\n",
    "        search (str): search term.\n",
    "    Returns:\n",
    "        dict: data for dcc.Download to trigger CSV download.\n",
    "    \"\"\"\n",
    "    filtered_df = df[\n",
    "        (df['character'] == character) &\n",
    "        (df['format'].isin(formats)) &\n",
    "        (df['date'] >= start_date) &\n",
    "        (df['date'] <= end_date)\n",
    "    ]\n",
    "    if search and search.strip():\n",
    "        filtered_df = filtered_df[\n",
    "            filtered_df['comic_title'].str.contains(search, case=False, na=False) |\n",
    "            filtered_df['event'].str.contains(search, case=False, na=False)\n",
    "        ]\n",
    "    return dcc.send_data_frame(filtered_df.to_csv, f\"marvel_comics_{character}.csv\")\n",
    "\n",
    "# run app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=8050)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
